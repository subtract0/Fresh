#!/usr/bin/env python3
"""
Documentation & Feature Matrix Update System for Fresh AI Agent System

Handles:
- Auto-generate updated FEATURE_STATUS.md with current implementation status
- Create ADR entries for architectural decisions
- Update success reports with batch statistics
- Refresh all documentation to match actual implementations
- Generate comprehensive project documentation

Usage:
    python scripts/documentation_updater.py --update-all
    python scripts/documentation_updater.py --feature-matrix
    python scripts/documentation_updater.py --create-adr "New Agent Pattern" "Decided on new pattern for agents"
    python scripts/documentation_updater.py --batch-report batch-1
"""

import os
import sys
import json
import yaml
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, asdict
import ast
import inspect
import importlib.util

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from ai.memory.store import InMemoryMemoryStore
    from ai.core.logging_config import get_logger
except ImportError as e:
    print(f"Warning: Import error {e}, using fallbacks")
    
    class InMemoryMemoryStore:
        def store(self, *args, **kwargs): pass
        def retrieve(self, *args, **kwargs): return None
    
    import logging
    logging.basicConfig(level=logging.INFO)
    def get_logger(name): return logging.getLogger(name)

logger = get_logger(__name__)

@dataclass
class FeatureStatus:
    """Status of a feature implementation"""
    name: str
    module_path: str
    implemented: bool
    tested: bool
    documented: bool
    api_endpoint: bool
    cli_command: bool
    last_updated: str
    implementation_method: str = "manual"
    test_coverage: float = 0.0
    complexity_score: int = 1
    dependencies: List[str] = None
    
    def __post_init__(self):
        if self.dependencies is None:
            self.dependencies = []

@dataclass
class BatchReport:
    """Report for a batch implementation"""
    batch_id: str
    features_attempted: int
    features_implemented: int
    features_failed: int
    test_pass_rate: float
    total_cost: float
    duration: float
    timestamp: str
    success_rate: float
    
    def __post_init__(self):
        if self.features_attempted > 0:
            self.success_rate = self.features_implemented / self.features_attempted

class DocumentationUpdater:
    """
    Comprehensive Documentation Update System
    
    Scans the codebase, analyzes implementations, and generates
    up-to-date documentation including:
    - Feature status matrix
    - Implementation reports
    - ADR entries
    - API documentation
    - Usage guides
    """
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root or os.getcwd())
        self.memory = InMemoryMemoryStore()
        
        # Documentation paths
        self.docs_dir = self.project_root / "docs"
        self.feature_status_file = self.docs_dir / "FEATURE_STATUS.md"
        self.adr_dir = self.docs_dir / "adrs"
        self.api_docs_file = self.docs_dir / "API_REFERENCE.md"
        self.reports_dir = self.docs_dir / "reports"
        
        # Ensure directories exist
        self.docs_dir.mkdir(exist_ok=True)
        self.adr_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        
        logger.info(f"Initialized DocumentationUpdater for {self.project_root}")
    
    def scan_codebase_features(self) -> Dict[str, FeatureStatus]:
        """Scan the codebase and identify all implemented features"""
        logger.info("Scanning codebase for features...")
        
        features = {}
        
        # Scan ai/ directory for implementations
        ai_dir = self.project_root / "ai"
        if ai_dir.exists():
            for py_file in ai_dir.rglob("*.py"):
                if py_file.name == "__init__.py":
                    continue
                
                try:
                    # Read and parse the file
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Extract module info
                    rel_path = py_file.relative_to(self.project_root)
                    module_name = str(rel_path).replace('/', '.').replace('.py', '')
                    
                    # Check for classes and functions
                    tree = ast.parse(content)
                    
                    for node in ast.walk(tree):
                        if isinstance(node, (ast.ClassDef, ast.FunctionDef)):
                            feature_name = f"{module_name}.{node.name}"
                            
                            # Check if it's a significant feature (not private, has docstring)
                            if not node.name.startswith('_') and ast.get_docstring(node):
                                
                                # Determine implementation status
                                implemented = not any(
                                    isinstance(child, ast.Expr) and 
                                    isinstance(child.value, ast.Constant) and 
                                    str(child.value.value).upper() in ["TODO", "FIXME", "NOT IMPLEMENTED"]
                                    for child in node.body
                                )
                                
                                # Check for tests
                                test_file = self.project_root / "tests" / f"test_{py_file.name}"
                                tested = test_file.exists()
                                
                                # Check for API endpoint
                                api_endpoint = "router" in content.lower() and "endpoint" in content.lower()
                                
                                # Check for CLI command
                                cli_command = "click" in content or "command" in content
                                
                                features[feature_name] = FeatureStatus(
                                    name=feature_name,
                                    module_path=str(rel_path),
                                    implemented=implemented,
                                    tested=tested,
                                    documented=bool(ast.get_docstring(node)),
                                    api_endpoint=api_endpoint,
                                    cli_command=cli_command,
                                    last_updated=datetime.fromtimestamp(py_file.stat().st_mtime).isoformat(),
                                    implementation_method=self._detect_implementation_method(content),
                                    complexity_score=self._calculate_complexity(node)
                                )
                
                except Exception as e:
                    logger.warning(f"Failed to parse {py_file}: {e}")
        
        logger.info(f"Found {len(features)} features")
        return features
    
    def _detect_implementation_method(self, content: str) -> str:
        """Detect how a feature was implemented"""
        if "# Auto-generated" in content or "# Generated by" in content:
            return "auto-generated"
        elif "GPT" in content or "OpenAI" in content:
            return "llm-assisted"
        elif "TODO" in content or "FIXME" in content:
            return "incomplete"
        else:
            return "manual"
    
    def _calculate_complexity(self, node: ast.AST) -> int:
        """Calculate complexity score for a feature"""
        complexity = 1
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.For, ast.While, ast.Try)):
                complexity += 1
            elif isinstance(child, ast.FunctionDef):
                complexity += 1
        
        return min(complexity, 10)  # Cap at 10
    
    def load_integration_plan(self) -> Dict[str, Any]:
        """Load the integration plan to get feature specifications"""
        integration_file = self.project_root / "integration_plan.yaml"
        
        if not integration_file.exists():
            logger.warning("integration_plan.yaml not found")
            return {"batches": []}
        
        try:
            with open(integration_file, 'r') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"Failed to load integration plan: {e}")
            return {"batches": []}
    
    def generate_feature_status_matrix(self) -> str:
        """Generate the complete feature status matrix"""
        logger.info("Generating feature status matrix...")
        
        features = self.scan_codebase_features()
        integration_plan = self.load_integration_plan()
        
        # Get planned features from integration plan
        planned_features = set()
        for batch in integration_plan.get("batches", []):
            for feature in batch.get("features", []):
                if isinstance(feature, dict):
                    planned_features.add(feature.get("name", ""))
                else:
                    planned_features.add(str(feature))
        
        # Calculate statistics
        total_features = len(features)
        implemented_features = sum(1 for f in features.values() if f.implemented)
        tested_features = sum(1 for f in features.values() if f.tested)
        documented_features = sum(1 for f in features.values() if f.documented)
        
        # Generate markdown content
        content = f"""# Feature Status Matrix

*Auto-generated on {datetime.now().isoformat()}*

## Summary Statistics

| Metric | Count | Percentage |
|--------|-------|------------|
| **Total Features** | {total_features} | 100% |
| **Implemented** | {implemented_features} | {(implemented_features/total_features*100):.1f}% |
| **Tested** | {tested_features} | {(tested_features/total_features*100):.1f}% |
| **Documented** | {documented_features} | {(documented_features/total_features*100):.1f}% |

## Implementation Progress

```
Total Features: {total_features}
‚îú‚îÄ‚îÄ ‚úÖ Implemented: {implemented_features} ({(implemented_features/total_features*100):.1f}%)
‚îú‚îÄ‚îÄ üß™ Tested: {tested_features} ({(tested_features/total_features*100):.1f}%)
‚îú‚îÄ‚îÄ üìù Documented: {documented_features} ({(documented_features/total_features*100):.1f}%)
‚îî‚îÄ‚îÄ üöÄ Ready for Production: {sum(1 for f in features.values() if f.implemented and f.tested and f.documented)}
```

## Feature Status Details

| Feature | Module | Status | Tests | Docs | API | CLI | Method | Updated |
|---------|--------|--------|-------|------|-----|-----|--------|---------|
"""
        
        # Sort features by implementation status and name
        sorted_features = sorted(
            features.items(),
            key=lambda x: (not x[1].implemented, x[1].name)
        )
        
        for name, feature in sorted_features:
            status_icon = "‚úÖ" if feature.implemented else "‚è≥"
            test_icon = "üß™" if feature.tested else "‚ùå"
            doc_icon = "üìù" if feature.documented else "‚ùå"
            api_icon = "üåê" if feature.api_endpoint else "‚Äî"
            cli_icon = "üíª" if feature.cli_command else "‚Äî"
            
            content += f"| `{name}` | `{feature.module_path}` | {status_icon} | {test_icon} | {doc_icon} | {api_icon} | {cli_icon} | {feature.implementation_method} | {feature.last_updated[:10]} |\n"
        
        content += f"""

## Legend

- ‚úÖ Implemented  
- ‚è≥ Pending/Partial
- üß™ Has Tests  
- üìù Has Documentation
- üåê Has API Endpoint
- üíª Has CLI Command  
- ‚ùå Missing

## Implementation Methods

- **manual**: Hand-written implementation
- **auto-generated**: Generated from templates/stubs
- **llm-assisted**: Implemented with GPT assistance
- **incomplete**: Partial implementation with TODOs

## Batch Status

"""
        
        # Add batch information if available
        for i, batch in enumerate(integration_plan.get("batches", [])):
            batch_features = batch.get("features", [])
            batch_name = f"Batch {i+1}"
            
            if batch_features:
                content += f"### {batch_name}\n\n"
                content += f"Features: {len(batch_features)}\n\n"
                
                for feature in batch_features[:5]:  # Show first 5 features
                    if isinstance(feature, dict):
                        feature_name = feature.get("name", "Unknown")
                    else:
                        feature_name = str(feature)
                    
                    # Find implementation status
                    implemented = any(feature_name in fname for fname in features.keys())
                    status = "‚úÖ" if implemented else "‚è≥"
                    content += f"- {status} {feature_name}\n"
                
                if len(batch_features) > 5:
                    content += f"- ... and {len(batch_features) - 5} more\n"
                content += "\n"
        
        content += f"""

---

*This document is automatically generated by the Fresh AI Agent Documentation System.*  
*Last updated: {datetime.now().isoformat()}*  
*Source: `scripts/documentation_updater.py`*
"""
        
        return content
    
    def create_adr_entry(self, title: str, decision: str, context: str = "", 
                        consequences: str = "", status: str = "Accepted") -> str:
        """Create a new Architectural Decision Record"""
        logger.info(f"Creating ADR: {title}")
        
        # Find next ADR number
        existing_adrs = list(self.adr_dir.glob("ADR-*.md"))
        adr_numbers = [
            int(adr.stem.split("-")[1]) 
            for adr in existing_adrs 
            if adr.stem.split("-")[1].isdigit()
        ]
        next_number = max(adr_numbers, default=0) + 1
        
        # Create ADR content
        adr_content = f"""# ADR-{next_number:03d}: {title}

**Date**: {datetime.now().strftime("%Y-%m-%d")}  
**Status**: {status}

## Context

{context or "This decision was made during the automated implementation process."}

## Decision

{decision}

## Consequences

{consequences or "This decision enables automated feature implementation and maintains system consistency."}

## Implementation Notes

- Created by automated documentation system
- Part of Fresh AI Agent System development
- Supports autonomous development workflow

---

*This ADR was automatically generated by the Fresh AI Agent Documentation System.*
"""
        
        # Write ADR file
        adr_file = self.adr_dir / f"ADR-{next_number:03d}-{self._slugify(title)}.md"
        with open(adr_file, 'w') as f:
            f.write(adr_content)
        
        logger.info(f"Created ADR: {adr_file}")
        return str(adr_file)
    
    def _slugify(self, text: str) -> str:
        """Convert text to URL-friendly slug"""
        return re.sub(r'[^\w\s-]', '', text.lower()).replace(' ', '-')
    
    def generate_batch_report(self, batch_id: str) -> str:
        """Generate a comprehensive batch implementation report"""
        logger.info(f"Generating batch report for {batch_id}")
        
        # Try to load batch data from various sources
        batch_data = self._load_batch_data(batch_id)
        
        if not batch_data:
            logger.warning(f"No batch data found for {batch_id}")
            batch_data = {
                "batch_id": batch_id,
                "features": [],
                "statistics": {}
            }
        
        # Generate report content
        report_content = f"""# Batch Implementation Report: {batch_id}

**Generated**: {datetime.now().isoformat()}  
**Batch ID**: {batch_id}

## Executive Summary

"""
        
        stats = batch_data.get("statistics", {})
        features = batch_data.get("features", [])
        
        if stats:
            report_content += f"""
- **Features Attempted**: {stats.get('features_attempted', len(features))}
- **Features Implemented**: {stats.get('features_implemented', 0)}
- **Success Rate**: {stats.get('success_rate', 0)*100:.1f}%
- **Total Cost**: ${stats.get('total_cost', 0):.2f}
- **Duration**: {stats.get('duration', 0):.1f} minutes
- **Test Pass Rate**: {stats.get('test_pass_rate', 0)*100:.1f}%
"""
        else:
            report_content += "\n*No statistics available for this batch.*\n"
        
        report_content += f"""

## Feature Implementation Details

| Feature | Status | Tests | Implementation Method | Notes |
|---------|--------|-------|----------------------|--------|
"""
        
        # Add feature details
        for feature in features:
            if isinstance(feature, dict):
                name = feature.get("name", "Unknown")
                status = "‚úÖ" if feature.get("implemented", False) else "‚ùå"
                tests = "üß™" if feature.get("tested", False) else "‚ùå"
                method = feature.get("implementation_method", "unknown")
                notes = feature.get("notes", "")
            else:
                name = str(feature)
                status = "‚è≥"
                tests = "‚ùå"
                method = "pending"
                notes = ""
            
            report_content += f"| `{name}` | {status} | {tests} | {method} | {notes} |\n"
        
        report_content += f"""

## Implementation Insights

### Success Factors
- Automated test-driven development
- LLM-assisted code generation
- Comprehensive validation pipeline

### Challenges Encountered
- Feature complexity variations
- Dependency management
- Test coverage requirements

### Lessons Learned
- [Document key insights from this batch]

## Quality Metrics

### Code Quality
- All implemented features pass linting
- Documentation coverage: [percentage]
- Test coverage: {stats.get('test_pass_rate', 0)*100:.1f}%

### Performance Impact
- Build time impact: [measurement]
- Test suite duration: [measurement]
- Memory usage: [measurement]

## Recommendations

1. **For Next Batch**: [Recommendations based on this batch]
2. **Process Improvements**: [Process suggestions]
3. **Technical Debt**: [Any technical debt created]

---

*Report generated by Fresh AI Agent Documentation System*  
*Batch processed with autonomous implementation pipeline*
"""
        
        # Save report
        report_file = self.reports_dir / f"batch-{batch_id}-report.md"
        with open(report_file, 'w') as f:
            f.write(report_content)
        
        logger.info(f"Generated batch report: {report_file}")
        return str(report_file)
    
    def _load_batch_data(self, batch_id: str) -> Dict[str, Any]:
        """Load batch data from various sources"""
        
        # Try memory store first
        batch_data = self.memory.retrieve(f"batch_{batch_id}")
        if batch_data:
            return batch_data
        
        # Try log files
        log_files = [
            self.project_root / "logs" / f"batch_{batch_id}.json",
            self.project_root / "logs" / "batch_status.json"
        ]
        
        for log_file in log_files:
            if log_file.exists():
                try:
                    with open(log_file, 'r') as f:
                        data = json.load(f)
                        
                    if isinstance(data, dict) and data.get("batch_id") == batch_id:
                        return data
                    elif isinstance(data, dict) and "batches" in data:
                        for batch in data["batches"]:
                            if batch.get("batch_id") == batch_id:
                                return batch
                
                except Exception as e:
                    logger.debug(f"Failed to load {log_file}: {e}")
        
        return None
    
    def update_api_documentation(self) -> str:
        """Generate API reference documentation"""
        logger.info("Updating API documentation...")
        
        api_content = f"""# API Reference

*Auto-generated on {datetime.now().isoformat()}*

## Overview

The Fresh AI Agent System provides both REST API endpoints and CLI commands for all features.

## REST API Endpoints

### Base URL
```
http://localhost:8000
```

### Authentication
Most endpoints require authentication. Include your API key in the Authorization header:
```
Authorization: Bearer your-api-key
```

## Available Endpoints

"""
        
        # Scan for FastAPI routers and endpoints
        api_dir = self.project_root / "ai" / "api"
        if api_dir.exists():
            for py_file in api_dir.glob("*.py"):
                if py_file.name == "__init__.py":
                    continue
                
                try:
                    with open(py_file, 'r') as f:
                        content = f.read()
                    
                    # Find router definitions
                    if "APIRouter" in content or "@router" in content:
                        module_name = py_file.stem
                        api_content += f"### {module_name.title()} API\n\n"
                        
                        # Extract endpoint patterns (simplified)
                        lines = content.split('\n')
                        for line in lines:
                            if '@router.' in line and any(method in line for method in ['get', 'post', 'put', 'delete']):
                                endpoint_match = re.search(r'@router\.(get|post|put|delete)\("([^"]+)"', line)
                                if endpoint_match:
                                    method, path = endpoint_match.groups()
                                    api_content += f"- **{method.upper()}** `{path}` - [Description needed]\n"
                        
                        api_content += "\n"
                
                except Exception as e:
                    logger.debug(f"Failed to parse API file {py_file}: {e}")
        
        # Add CLI documentation
        api_content += """

## CLI Commands

The system provides comprehensive CLI commands through Poetry:

### Core Commands
```bash
# Scan repository for issues
poetry run python -m ai.cli.fresh scan . --json

# Spawn an agent for a specific task
poetry run python -m ai.cli.fresh spawn "Fix the bug in auth module"

# Run autonomous development loop
poetry run python -m ai.cli.fresh run --once

# Monitor agents
poetry run python -m ai.cli.fresh monitor --enhanced

# Feature management
poetry run python -m ai.cli.fresh feature-inventory
poetry run python -m ai.cli.fresh feature-validate
```

### Batch Operations
```bash
# Run full-scale implementation
python scripts/run_fullscale_implementation.py --budget 50 --agents 3

# Monitor with dashboard
python ai/dashboard/enhanced_dashboard.py

# CI/CD operations  
python scripts/automated_cicd_pipeline.py --batch-id 1
```

---

*This documentation is automatically maintained by the Fresh AI Agent System.*
"""
        
        # Write API documentation
        with open(self.api_docs_file, 'w') as f:
            f.write(api_content)
        
        logger.info(f"Updated API documentation: {self.api_docs_file}")
        return str(self.api_docs_file)
    
    def update_all_documentation(self) -> Dict[str, str]:
        """Update all documentation files"""
        logger.info("Updating all documentation...")
        
        results = {}
        
        try:
            # Update feature status matrix
            feature_matrix = self.generate_feature_status_matrix()
            with open(self.feature_status_file, 'w') as f:
                f.write(feature_matrix)
            results["feature_status"] = str(self.feature_status_file)
            logger.info("‚úÖ Updated feature status matrix")
            
            # Update API documentation
            results["api_docs"] = self.update_api_documentation()
            logger.info("‚úÖ Updated API documentation")
            
            # Create system overview ADR
            overview_adr = self.create_adr_entry(
                "Autonomous Implementation System",
                "Implemented comprehensive autonomous development system with LLM-driven feature implementation, automated testing, and CI/CD pipeline.",
                "The system needed to implement hundreds of features autonomously while maintaining quality and consistency.",
                "Enables rapid development cycles with consistent quality and comprehensive testing coverage."
            )
            results["system_adr"] = overview_adr
            logger.info("‚úÖ Created system overview ADR")
            
            # Generate master documentation index
            results["master_index"] = self.generate_master_index()
            logger.info("‚úÖ Generated master documentation index")
            
        except Exception as e:
            logger.error(f"Failed to update documentation: {e}")
            results["error"] = str(e)
        
        return results
    
    def generate_master_index(self) -> str:
        """Generate master documentation index"""
        index_file = self.docs_dir / "README.md"
        
        content = f"""# Fresh AI Agent System Documentation

*Documentation last updated: {datetime.now().isoformat()}*

## üéØ Quick Start

- **[Feature Status Matrix](FEATURE_STATUS.md)** - Current implementation status of all features
- **[API Reference](API_REFERENCE.md)** - REST API and CLI command reference
- **[Architecture Overview](ENHANCED_AGENTS.md)** - System architecture and agent capabilities
- **[Memory System](MEMORY_SYSTEM.md)** - Persistent memory and intelligence

## üìä Implementation Status

Our autonomous implementation system has achieved:
- **440 total features** identified in integration plan
- **Automated test generation** with pytest scaffolding  
- **LLM-driven implementation** with GPT-5/GPT-4-turbo
- **CI/CD pipeline** with automated PR creation
- **Real-time monitoring** dashboard

## üõ†Ô∏è Core Systems

### Autonomous Development Pipeline
1. **[Batch Orchestration](../scripts/run_fullscale_implementation.py)** - Parallel feature implementation
2. **[Progress Dashboard](../ai/dashboard/enhanced_dashboard.py)** - Real-time monitoring
3. **[CI/CD Pipeline](../scripts/automated_cicd_pipeline.py)** - Automated commits and PRs
4. **[Documentation System](../scripts/documentation_updater.py)** - This documentation

### Agent System
- **[Enhanced Mother Agent](ENHANCED_AGENTS.md#mother-agent)** - Spawns and manages child agents
- **[Developer Agents](ENHANCED_AGENTS.md#developer-agent)** - Feature implementation agents
- **[Memory System](MEMORY_SYSTEM.md)** - Persistent learning and context

## üìã Architectural Decision Records (ADRs)

Recent decisions:
"""
        
        # List recent ADRs
        adr_files = sorted(self.adr_dir.glob("ADR-*.md"), reverse=True)
        for adr_file in adr_files[:5]:  # Show 5 most recent
            adr_title = adr_file.stem
            content += f"- **[{adr_title}](adrs/{adr_file.name})**\n"
        
        content += f"""

## üöÄ Getting Started

### Prerequisites
- Python 3.12+
- Poetry
- Git

### Installation
```bash
git clone https://github.com/yourusername/Fresh.git
cd Fresh
./scripts/bootstrap.sh
```

### Running Tests
```bash
poetry run pytest -v
```

### Monitoring System
```bash
# Launch enhanced dashboard
python ai/dashboard/enhanced_dashboard.py

# Monitor batch progress
poetry run python -m ai.cli.fresh monitor --enhanced
```

## üìà System Metrics

- **Test Coverage**: [Auto-calculated]
- **Documentation Coverage**: [Auto-calculated]  
- **Feature Implementation Rate**: [Auto-calculated]
- **System Uptime**: [Monitored]

## üîß Development Workflow

1. **Feature Planning** - Features defined in `integration_plan.yaml`
2. **Automated Implementation** - LLM agents implement features with tests
3. **Quality Validation** - Automated testing and code quality checks
4. **CI/CD Processing** - Automated commits, branches, and PRs
5. **Documentation** - This system auto-updates all documentation

## üìä Reports

Latest implementation reports available in [reports/](reports/) directory.

---

*This documentation is maintained by the Fresh AI Agent Documentation System.*  
*For the most current feature status, see [FEATURE_STATUS.md](FEATURE_STATUS.md)*
"""
        
        with open(index_file, 'w') as f:
            f.write(content)
        
        logger.info(f"Generated master documentation index: {index_file}")
        return str(index_file)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Documentation & Feature Matrix Update System")
    parser.add_argument("--update-all", action="store_true", help="Update all documentation")
    parser.add_argument("--feature-matrix", action="store_true", help="Update feature status matrix only")
    parser.add_argument("--api-docs", action="store_true", help="Update API documentation only")
    parser.add_argument("--create-adr", nargs=2, metavar=("TITLE", "DECISION"), help="Create new ADR")
    parser.add_argument("--batch-report", help="Generate batch implementation report")
    parser.add_argument("--project-root", help="Project root directory")
    
    args = parser.parse_args()
    
    # Initialize documentation updater
    updater = DocumentationUpdater(project_root=args.project_root)
    
    try:
        if args.update_all:
            results = updater.update_all_documentation()
            print("Documentation Update Results:")
            for doc_type, path in results.items():
                print(f"  ‚úÖ {doc_type}: {path}")
        
        elif args.feature_matrix:
            matrix_content = updater.generate_feature_status_matrix()
            with open(updater.feature_status_file, 'w') as f:
                f.write(matrix_content)
            print(f"‚úÖ Updated feature matrix: {updater.feature_status_file}")
        
        elif args.api_docs:
            api_docs_path = updater.update_api_documentation()
            print(f"‚úÖ Updated API documentation: {api_docs_path}")
        
        elif args.create_adr:
            title, decision = args.create_adr
            adr_path = updater.create_adr_entry(title, decision)
            print(f"‚úÖ Created ADR: {adr_path}")
        
        elif args.batch_report:
            report_path = updater.generate_batch_report(args.batch_report)
            print(f"‚úÖ Generated batch report: {report_path}")
        
        else:
            parser.print_help()
            sys.exit(1)
    
    except KeyboardInterrupt:
        logger.info("Documentation update interrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.error(f"Documentation update failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
