#!/usr/bin/env python3
"""
üöÄ AUTONOMOUS BATCH IMPLEMENTATION RUNNER

Execute the parallel implementation of 440+ features using OpenAI API workers
with real-time progress tracking, cost monitoring, and safety controls.

Usage:
    python scripts/run_batch_implementation.py [options]

Examples:
    # Run with default settings (3 parallel batches, $200 budget)
    python scripts/run_batch_implementation.py

    # Conservative run (1 batch at a time, $50 budget)
    python scripts/run_batch_implementation.py --max-parallel-batches 1 --max-cost 50

    # Aggressive run (5 parallel batches, $500 budget, no auto-commit)
    python scripts/run_batch_implementation.py --max-parallel-batches 5 --max-cost 500 --no-auto-commit

    # Dry run to see progress monitoring without implementation
    python scripts/run_batch_implementation.py --dry-run
"""
from __future__ import annotations

import asyncio
import argparse
import json
import logging
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any

# Add project root to path
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from ai.orchestration.batch_runner import (
    BatchImplementationOrchestrator, 
    OrchestrationConfig,
    run_batch_implementation
)
from ai.tools.memory_tools import WriteMemory


def setup_logging(verbose: bool = False, log_file: Optional[str] = None) -> None:
    """Configure logging for the batch runner."""
    level = logging.DEBUG if verbose else logging.INFO
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(level)
    
    # File handler if specified
    handlers = [console_handler]
    if log_file:
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.DEBUG)
        handlers.append(file_handler)
    
    # Configure root logger
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )
    
    # Suppress noisy loggers
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('openai').setLevel(logging.WARNING)


def create_config_from_args(args) -> OrchestrationConfig:
    """Create orchestration config from command line arguments."""
    return OrchestrationConfig(
        max_parallel_batches=args.max_parallel_batches,
        max_parallel_features_per_batch=args.max_parallel_features,
        max_cost_per_batch_usd=args.max_cost_per_batch,
        max_total_cost_usd=args.max_cost,
        auto_commit_after_batch=not args.no_auto_commit,
        auto_create_pr=not args.no_auto_pr,
        openai_model=args.model,
        temperature=args.temperature,
        timeout_per_feature_minutes=args.timeout
    )


async def run_with_progress_monitoring(
    config: OrchestrationConfig,
    plan_path: str,
    dry_run: bool = False
) -> Dict[str, Any]:
    """Run batch implementation with real-time progress monitoring."""
    if dry_run:
        print("üèÉ DRY RUN MODE - No actual implementation will be performed")
        return {
            "dry_run": True,
            "message": "Dry run completed successfully",
            "total_features": 440,
            "estimated_cost": 150.0,
            "estimated_time_hours": 12.5
        }
    
    orchestrator = BatchImplementationOrchestrator(config)
    await orchestrator.initialize()
    
    print(f"üéØ Starting batch implementation orchestration: {orchestrator.orchestration_id}")
    print(f"üìä Budget: ${config.max_total_cost_usd:.2f} | Parallel batches: {config.max_parallel_batches}")
    print(f"üîß Model: {config.openai_model} | Auto-commit: {config.auto_commit_after_batch}")
    print("=" * 60)
    
    # Start progress monitoring task
    async def progress_monitor():
        while True:
            try:
                summary = orchestrator.get_progress_summary()
                
                if summary['total_features'] > 0:
                    print(f"\r‚ö° Progress: {summary['progress_percentage']:.1f}% "
                          f"({summary['completed_features']}/{summary['total_features']} features) "
                          f"| Cost: ${summary['total_cost_usd']:.2f} "
                          f"| Time: {summary['execution_time_minutes']:.1f}m", end='')
                
                await asyncio.sleep(10)  # Update every 10 seconds
                
            except Exception as e:
                # Silent failure in progress monitoring
                await asyncio.sleep(30)
    
    # Start monitoring task
    monitor_task = asyncio.create_task(progress_monitor())
    
    try:
        # Execute all batches
        summary = await orchestrator.execute_all_batches(plan_path)
        
        # Stop progress monitoring
        monitor_task.cancel()
        
        print(f"\n\nüéâ BATCH IMPLEMENTATION COMPLETE!")
        print("=" * 60)
        print(f"‚úÖ Successful batches: {summary['successful_batches']}/{summary['total_batches']}")
        print(f"üéØ Features implemented: {summary['implemented_features']}/{summary['total_features']}")
        print(f"üí∞ Total cost: ${summary['total_cost_usd']:.2f}")
        print(f"‚è±Ô∏è  Execution time: {summary['execution_time_hours']:.1f} hours")
        print(f"üí° Average cost per feature: ${summary['average_cost_per_feature']:.2f}")
        
        return summary
        
    except Exception as e:
        monitor_task.cancel()
        raise e


def save_execution_report(summary: Dict[str, Any], output_file: str) -> None:
    """Save execution summary to file."""
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Enhanced summary with metadata
    report = {
        "timestamp": datetime.now().isoformat(),
        "execution_summary": summary,
        "metadata": {
            "runner_version": "1.0",
            "fresh_ai_system": "v0.2-auto-hookups",
            "report_generator": "scripts/run_batch_implementation.py"
        }
    }
    
    output_path.write_text(json.dumps(report, indent=2))
    print(f"üìÑ Execution report saved to: {output_file}")


def main():
    """Main entry point for the batch implementation runner."""
    parser = argparse.ArgumentParser(
        description="Execute autonomous batch feature implementation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    # Execution parameters
    parser.add_argument(
        "--plan-path", 
        default="docs/hookup_analysis/integration_plan.yaml",
        help="Path to integration plan YAML file"
    )
    parser.add_argument(
        "--max-parallel-batches", 
        type=int, 
        default=3,
        help="Maximum number of batches to run in parallel"
    )
    parser.add_argument(
        "--max-parallel-features", 
        type=int, 
        default=5,
        help="Maximum features per batch to implement in parallel"
    )
    parser.add_argument(
        "--max-cost", 
        type=float, 
        default=200.0,
        help="Maximum total cost budget in USD"
    )
    parser.add_argument(
        "--max-cost-per-batch", 
        type=float, 
        default=25.0,
        help="Maximum cost per batch in USD"
    )
    
    # OpenAI parameters
    parser.add_argument(
        "--model", 
        default="gpt-4",
        choices=["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
        help="OpenAI model to use for implementation"
    )
    parser.add_argument(
        "--temperature", 
        type=float, 
        default=0.1,
        help="OpenAI temperature (0.0-1.0, lower = more deterministic)"
    )
    parser.add_argument(
        "--timeout", 
        type=int, 
        default=10,
        help="Timeout per feature implementation in minutes"
    )
    
    # Automation options
    parser.add_argument(
        "--no-auto-commit", 
        action="store_true",
        help="Disable automatic commits after each batch"
    )
    parser.add_argument(
        "--no-auto-pr", 
        action="store_true",
        help="Disable automatic PR creation"
    )
    parser.add_argument(
        "--dry-run", 
        action="store_true",
        help="Show progress monitoring without actual implementation"
    )
    
    # Output options
    parser.add_argument(
        "--output", 
        default="ai/logs/batch_implementation_report.json",
        help="Output file for execution report"
    )
    parser.add_argument(
        "--log-file",
        help="Log file path (default: console only)"
    )
    parser.add_argument(
        "--verbose", "-v", 
        action="store_true",
        help="Enable verbose logging"
    )
    
    args = parser.parse_args()
    
    # Setup logging
    setup_logging(args.verbose, args.log_file)
    
    # Validate plan file exists
    plan_file = Path(args.plan_path)
    if not plan_file.exists() and not args.dry_run:
        print(f"‚ùå Integration plan not found: {args.plan_path}")
        print("üí° Run 'python scripts/inventory_codebase.py' to generate the plan")
        return 1
    
    # Create configuration
    config = create_config_from_args(args)
    
    # Record execution start in memory
    WriteMemory(
        content=f"Started batch implementation runner with config: {config}",
        tags=["batch_implementation", "runner", "start"]
    ).run()
    
    print("ü§ñ AUTONOMOUS BATCH IMPLEMENTATION RUNNER")
    print("=" * 60)
    print(f"üìÖ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìã Plan: {args.plan_path}")
    print(f"üí∞ Budget: ${config.max_total_cost_usd:.2f}")
    print(f"üîß Model: {config.openai_model}")
    print()
    
    try:
        # Run the batch implementation
        summary = asyncio.run(run_with_progress_monitoring(
            config=config,
            plan_path=args.plan_path,
            dry_run=args.dry_run
        ))
        
        # Save execution report
        if not args.dry_run:
            save_execution_report(summary, args.output)
        
        # Record success in memory
        WriteMemory(
            content=f"Batch implementation completed successfully: {summary.get('implemented_features', 0)} features",
            tags=["batch_implementation", "success", "complete"]
        ).run()
        
        print(f"\nüèÜ SUCCESS! Batch implementation completed successfully")
        return 0
        
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è  Interrupted by user - cleaning up...")
        WriteMemory(
            content="Batch implementation interrupted by user",
            tags=["batch_implementation", "interrupted"]
        ).run()
        return 130
        
    except Exception as e:
        print(f"\n‚ùå FAILED: {e}")
        
        # Record failure in memory
        WriteMemory(
            content=f"Batch implementation failed: {str(e)[:200]}",
            tags=["batch_implementation", "error", "failed"]
        ).run()
        
        if args.verbose:
            import traceback
            traceback.print_exc()
            
        return 1


if __name__ == "__main__":
    sys.exit(main())
