"""
API endpoint for OpenAIUsageTracker
Generated by Advanced Feature Stub Generator
"""
from datetime import datetime
from threading import Lock
from typing import Optional, Dict, Any

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field, root_validator

router = APIRouter()

# Threadâ€“safe in-memory usage store
_usage_stats: Dict[str, Dict[str, int]] = {}
_usage_lock: Lock = Lock()


class OpenAIUsageTrackerRequest(BaseModel):
    """
    Request model for OpenAIUsageTracker.

    action:
        - "log":   Log a new usage entry. Requires user_id, endpoint, prompt_tokens, completion_tokens.
        - "stats": Retrieve usage statistics. If user_id provided, returns stats for that user,
                   otherwise returns aggregate stats.
    """
    action: str = Field(..., regex="^(log|stats)$")
    user_id: Optional[str] = Field(
        None,
        description="Unique identifier for the user whose usage is being logged or queried.",
    )
    endpoint: Optional[str] = Field(
        None, description="OpenAI endpoint that was called (e.g., 'chat.completions')."
    )
    prompt_tokens: Optional[int] = Field(
        None, ge=0, description="Number of prompt tokens consumed by the request."
    )
    completion_tokens: Optional[int] = Field(
        None, ge=0, description="Number of completion tokens consumed by the request."
    )
    metadata: Optional[Dict[str, Any]] = Field(
        None, description="Additional metadata for future extensibility."
    )

    @root_validator
    def validate_fields_for_action(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        """Ensure required fields are provided based on the requested action."""
        action = values.get("action")
        if action == "log":
            missing = [
                field
                for field in ("user_id", "endpoint", "prompt_tokens", "completion_tokens")
                if not values.get(field) and values.get(field) != 0
            ]
            if missing:
                raise ValueError(
                    f"Missing required field(s) for 'log' action: {', '.join(missing)}"
                )
        return values


class OpenAIUsageTrackerResponse(BaseModel):
    """Response model for OpenAIUsageTracker."""
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None
    timestamp: datetime = Field(default_factory=datetime.utcnow)


def _update_usage_stats(
    user_id: str, prompt_tokens: int, completion_tokens: int
) -> Dict[str, Any]:
    """
    Update the in-memory usage statistics in a thread-safe fashion.

    Returns the updated statistics for the specified user.
    """
    with _usage_lock:
        user_stats = _usage_stats.setdefault(
            user_id, {"prompt_tokens": 0, "completion_tokens": 0, "requests": 0}
        )
        user_stats["prompt_tokens"] += prompt_tokens
        user_stats["completion_tokens"] += completion_tokens
        user_stats["requests"] += 1
        # Return a copy to avoid accidental external mutation
        return dict(user_stats)


def _get_usage_stats(user_id: Optional[str] = None) -> Dict[str, Any]:
    """
    Retrieve usage statistics. If user_id is provided, returns stats for that user,
    otherwise returns aggregate statistics for all users.
    """
    with _usage_lock:
        if user_id:
            stats = _usage_stats.get(user_id, {"prompt_tokens": 0, "completion_tokens": 0, "requests": 0})
            return {user_id: dict(stats)}
        # Aggregate totals across all users
        aggregate = {"prompt_tokens": 0, "completion_tokens": 0, "requests": 0}
        for stats in _usage_stats.values():
            aggregate["prompt_tokens"] += stats["prompt_tokens"]
            aggregate["completion_tokens"] += stats["completion_tokens"]
            aggregate["requests"] += stats["requests"]
        return {"aggregate": aggregate, "per_user": {k: dict(v) for k, v in _usage_stats.items()}}


@router.post("/api/v1/OpenAIUsageTracker", response_model=OpenAIUsageTrackerResponse)
async def openaiusagetracker_endpoint(
    request: OpenAIUsageTrackerRequest,
) -> OpenAIUsageTrackerResponse:
    """
    OpenAIUsageTracker endpoint.

    Supports two actions:
      - "log":   Log usage information.
      - "stats": Retrieve usage statistics.
    """
    try:
        if request.action == "log":
            updated_stats = _update_usage_stats(
                user_id=request.user_id,
                prompt_tokens=request.prompt_tokens,
                completion_tokens=request.completion_tokens,
            )
            result_data = {
                "user_id": request.user_id,
                "updated_stats": updated_stats,
                "detail": "Usage logged successfully",
            }
            message = "Usage log recorded."
        else:  # action == "stats"
            stats = _get_usage_stats(user_id=request.user_id)
            result_data = {"stats": stats}
            message = "Usage statistics retrieved."

        return OpenAIUsageTrackerResponse(success=True, message=message, data=result_data)

    except ValueError as ve:
        # Validation error not caught by Pydantic root_validator
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:  # pragma: no cover
        # Catch-all for unexpected exceptions
        raise HTTPException(
            status_code=500,
            detail=f"OpenAIUsageTracker execution failed: {str(e)}",
        ) from e


# Export router for main application
__all__ = ["router", "OpenAIUsageTrackerRequest", "OpenAIUsageTrackerResponse"]